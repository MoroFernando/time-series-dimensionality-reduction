{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a5a8a1b",
   "metadata": {},
   "source": [
    "Este notebook pretende analisar a preservação estrutural de series temporais após redução de dimensionalidade. Para isso serão selecionados datasets com alta dimensionalidade da biblioteca AEON e aplicados variações do algoritimo do PAA (Piecewise Aggregate Approximation) para redução de dimensionalidade aplicando diferentes taxas perceptuais de redução.\n",
    "\n",
    "Para medir essa preservação da estrutura iremos calcular uma matriz de distâncias de cada série temporal antes e depois da redução de dimensionalidade utilizando a distância euclidiana. Assim poderemos comparar se após a redução de dimensionalidade os K vizinhos mais próximos de cada série temporal permanecem os mesmos.\n",
    "\n",
    "A partir da quantidade de vizinhos preservados após a redução de dimensionalidade, será calculada uma métrica de preservação estrutural definida como um valor entre 0 e 1, onde 1 indica que todos os K vizinhos mais próximos permaneceram os mesmos e 0 indica que nenhum vizinho próximo permaneceu o mesmo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9712d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa algumas bibliotecas necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from aeon.datasets import load_classification\n",
    "from aeon.distances import euclidean_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "433f2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Começamos definindo a lista de datasets que serão utilizados para os experimentos\n",
    "# Estes são datasets de alta dimensionalidade da biblioteca AEON\n",
    "high_dim_datasets = [\n",
    "  'ACSF1',\n",
    "  'CinCECGTorso',\n",
    "  'EOGHorizontalSignal',\n",
    "  'EOGVerticalSignal',\n",
    "  'EthanolLevel',\n",
    "  'HandOutlines',\n",
    "  'Haptics',\n",
    "  'HouseTwenty',\n",
    "  'InlineSkate',\n",
    "  'Mallat',\n",
    "  'MixedShapesRegularTrain',\n",
    "  'MixedShapesSmallTrain',\n",
    "  'Phoneme',\n",
    "  'PigAirwayPressure',\n",
    "  'PigArtPressure',\n",
    "  'PigCVP',\n",
    "  'Rock',\n",
    "  'SemgHandGenderCh2',\n",
    "  'SemgHandMovementCh2',\n",
    "  'SemgHandSubjectCh2',\n",
    "  'StarLightCurves',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3f1d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para facilitar a comparação de séries em diferentes escalas, \n",
    "# podemos aplicar uma função de normalização nas séries.\n",
    "# Assim todas as séries ficarão com média 0 e desvio padrão 1.\n",
    "def znorm(x):\n",
    "  x_znorm = (x - np.mean(x)) / np.std(x)\n",
    "  return x_znorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a6925ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as funções de agregação que podem ser usadas para reduzir a dimensionalidade no PAA\n",
    "aggregations = {\n",
    "    'average': lambda x: np.mean(x),\n",
    "    'median': lambda x: np.median(x),\n",
    "    'max': lambda x: np.max(x),\n",
    "    'min': lambda x: np.min(x),\n",
    "    'sum': lambda x: np.sum(x),\n",
    "    'variance': lambda x: np.var(x),\n",
    "    'std': lambda x: np.std(x),\n",
    "    'iqr': lambda x: np.subtract(*np.percentile(x, [75, 25])),\n",
    "    'first': lambda x: x[0],\n",
    "    'central': lambda x: x[len(x)//2],\n",
    "    'last': lambda x: x[-1],\n",
    "    'max-min': lambda x: np.max(x) - np.min(x),\n",
    "    'avg-max': lambda x: np.abs((np.mean(x) - np.max(x))),\n",
    "    'avg-min': lambda x: np.abs((np.mean(x) - np.min(x))),\n",
    "    'random': lambda x: np.random.choice(x)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f536602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementa o algoritmo PAA (Piecewise Aggregate Approximation)\n",
    "# Recebe uma série temporal 's', o tamanho desejado 'w' e a função de agregação 'agg'\n",
    "def PAA(s, w, agg='average'):\n",
    "    if agg not in aggregations:\n",
    "        raise ValueError(f\"Função de agregação '{agg}' é inválida ou não suportada.\")\n",
    "\n",
    "    n = len(s)\n",
    "    s = np.array(s)\n",
    "\n",
    "    # Aqui criamos n valores uniformemente espaçados entre 0 e w (exclusivo).\n",
    "    # Por exemplo: n=6 e w=2 será [0,0,0,1,1,1]\n",
    "    idx = np.floor(np.linspace(0, w, n, endpoint=False)).astype(int)\n",
    "\n",
    "    # Aqui iteramos sobre o tamanho desejado 'w' e aplicamos uma máscara para selecionar os pontos da série que pertencem a cada segmento.\n",
    "    # Por exemplo: n=6 e w=2, o idx resultante será: \n",
    "    #              [True, True, True, False, False, False] para w = 0\n",
    "    #              Assim podemos selecionar os pontos da série que pertencem a cada segmento.\n",
    "    res = [aggregations[agg](s[idx == i]) for i in range(w)]\n",
    "    # Normalizamos a série reduzida utilizando Z-Norm\n",
    "    res = znorm(res)\n",
    "\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e790e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as taxas de redução de dimensionalidade a serem testadas\n",
    "reduction_rates = [\n",
    "    0.9,\n",
    "    0.8,\n",
    "    0.7,\n",
    "    0.6,\n",
    "    0.5,\n",
    "    0.4,\n",
    "    0.3,\n",
    "    0.2,\n",
    "    0.1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54520ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa a função para calcular distâncias de forma eficiente\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Função para calcular a matriz de distância entre todas as séries temporais em um conjunto de dados X\n",
    "def get_distance_matrix(X):\n",
    "    # 1. Cria uma cópia de X para evitar modificar o original\n",
    "    X_cp = np.array(X)\n",
    "\n",
    "    # 2. Remove dimensões unitárias para garantir que X seja 2D (N x M)\n",
    "    # Por se tratar de séries temporais univariadas, o formato original é \n",
    "    # (N x 1 x M) e sera convertido para (N x M)\n",
    "    X_2d = X_cp.squeeze()\n",
    "\n",
    "    # 3. pdist calcula as N*(N-1)/2 distâncias únicas\n",
    "    condensed_dist = pdist(X_2d, metric='euclidean')\n",
    "\n",
    "    # 4. squareform monta a matriz N x N simétrica completa\n",
    "    distance_matrix = squareform(condensed_dist)\n",
    "    \n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c53c6a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter os K vizinhos mais proximos de uma serie (s) por meio de uma matriz de distâncias\n",
    "def get_k_nearest_neighbors(dist_matrix, point_idx, k):    \n",
    "    # 1. Pega a linha de distâncias para o nosso ponto\n",
    "    distances_from_point = dist_matrix[point_idx]\n",
    "    \n",
    "    # 2. Obtém os índices ordenados pela distância\n",
    "    #    Ex: sorted_indices[0] será o próprio point_idx (dist 0)\n",
    "    sorted_indices = np.argsort(distances_from_point)\n",
    "    \n",
    "    # 3. Pega os K vizinhos mais próximos.\n",
    "    #    Pulamos o primeiro índice (posição 0), pois é o próprio ponto.\n",
    "    #    Pegamos da posição 1 (o vizinho mais próximo) até k+1.\n",
    "    k_nearest_indices = sorted_indices[1 : k + 1]\n",
    "    \n",
    "    # 4. Pega as distâncias correspondentes a esses vizinhos\n",
    "    k_nearest_distances = distances_from_point[k_nearest_indices]\n",
    "    \n",
    "    return k_nearest_indices, k_nearest_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd970050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'HouseTwenty' carregado com 159 séries temporais, cada uma com dimensão de 2000.\n"
     ]
    }
   ],
   "source": [
    "# Escolhe um dataset de alta dimensionalidade para testar\n",
    "d = 'HouseTwenty'\n",
    "\n",
    "# Carrega o dataset completo (train + test)\n",
    "X, _ = load_classification(d, split=None)\n",
    "\n",
    "# Exibe informações sobre o shape do dataset carregado\n",
    "print(f\"Dataset '{d}' carregado com {X.shape[0]} séries temporais, cada uma com dimensão de {X.shape[2]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b09e7e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Distância (Início):\n",
      "[[ 0.         56.13328025 54.34043454 54.15500871 67.07087115]\n",
      " [56.13328025  0.         61.12841113 62.47950359 63.62144155]\n",
      " [54.34043454 61.12841113  0.         46.69631666 66.82907255]\n",
      " [54.15500871 62.47950359 46.69631666  0.         67.17988739]\n",
      " [67.07087115 63.62144155 66.82907255 67.17988739  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Normaliza as séries com Z-Norm\n",
    "X_norm = np.array([[znorm(s[0])] for s in X]) # Para cada série s em X, aplica znorm em s[0] (a série em si)\n",
    "\n",
    "# Calcula a matriz de distância entre todas as séries normalizadas\n",
    "dist_matrix = get_distance_matrix(X_norm)\n",
    "\n",
    "# Exibe uma prévia da matriz de distância calculada com apenas os primeiros 5x5 elementos\n",
    "print(f\"Matriz de Distância (Início):\")\n",
    "print(dist_matrix[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d031a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séries mais próximas da série 5: [139 107   3] com distâncias [44.33162092 46.05375307 47.36015159]\n"
     ]
    }
   ],
   "source": [
    "# Testa a função de obtenção dos K vizinhos mais próximos\n",
    "s_idx = 5  # Índice da série que queremos analisar\n",
    "k = 3 # Número de vizinhos mais próximos a serem encontrados\n",
    "\n",
    "# Obtém os K vizinhos mais próximos\n",
    "nearest_indices, nearest_distances = get_k_nearest_neighbors(dist_matrix, s_idx, k)\n",
    "print(f'Séries mais próximas da série {s_idx}: {nearest_indices} com distâncias {nearest_distances}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3d3399",
   "metadata": {},
   "source": [
    "Na sequencia iremos reduzir a dimensionalidade das séries temporais utilizando o PAA e calcular novamente a matriz de distâncias e os K vizinhos mais próximos para comparar com os resultados obtidos anteriormente com a matriz de distâncias original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "441cfdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Distância Reduzida (Início):\n",
      "[[ 0.         39.33083987 37.74750816 38.00517818 47.60069307]\n",
      " [39.33083987  0.         43.17980888 44.15346848 45.00745588]\n",
      " [37.74750816 43.17980888  0.         32.04276567 47.45108226]\n",
      " [38.00517818 44.15346848 32.04276567  0.         47.59783525]\n",
      " [47.60069307 45.00745588 47.45108226 47.59783525  0.        ]]\n",
      "Séries mais próximas da série 5: [139 107   3] com distâncias [29.95126277 32.07611833 33.22822385]\n"
     ]
    }
   ],
   "source": [
    "# Carrega o dataset novamente para aplicar a redução de dimensionalidade\n",
    "X_2, _ = load_classification(d, split=None)\n",
    "# Obtem o tamnho (dimensão) das séries temporais\n",
    "original_length = len(X_2[0][0])\n",
    "\n",
    "agg = 'median' # Definie a função de agregação\n",
    "reduction_rate = 0.5 # Define a taxa de redução %\n",
    "w = int(original_length * (1 - reduction_rate)) # Calcula o tamnaho w da seria apos reduzir pela taxa definida\n",
    "\n",
    "# Reduz a dimensionalidade das séries utilizando PAA com os parâmetros definidos\n",
    "X_reduced = np.array([[PAA(s[0], w, agg=agg)] for s in X_2])\n",
    "\n",
    "# Calcula a nova matriz de distâncias com as séries reduzidas\n",
    "dist_matrix_reduced = get_distance_matrix(X_reduced)\n",
    "\n",
    "# Exibe a nova matriz de distâncias primeiro 5x5 elementos\n",
    "print(f\"Matriz de Distância Reduzida (Início):\")\n",
    "print(dist_matrix_reduced[:5, :5])\n",
    "\n",
    "# Exibe as k=3 series mais próximas de uma series qualquer do dataset reduzido\n",
    "reduced_s_idx = 5  # Índice da série que queremos analisar\n",
    "\n",
    "reduced_nearest_indices, reduced_nearest_distances = get_k_nearest_neighbors(dist_matrix_reduced, reduced_s_idx, k)\n",
    "print(f'Séries mais próximas da série {reduced_s_idx}: {reduced_nearest_indices} com distâncias {reduced_nearest_distances}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30c0a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora definimos uma função que calcula a métrica de semelhança da serie reduzida\n",
    "# Essa métrica levara em conta a porcentagem de K vizinhos que permaneceram os mesmos apos a redução da dimensionalidade\n",
    "\n",
    "def calculate_k_similarity(original_neighbors, reduced_neighbors):\n",
    "    # Converte os arrays de índices em conjuntos para facilitar a comparação\n",
    "    set_original = set(original_neighbors)\n",
    "    set_reduced = set(reduced_neighbors)\n",
    "    \n",
    "    # Calcula a interseção dos dois conjuntos para encontrar os vizinhos comuns\n",
    "    common_neighbors = set_original.intersection(set_reduced)\n",
    "    \n",
    "    # Calcula a similaridade como a proporção de vizinhos comuns em relação a K\n",
    "    similarity = len(common_neighbors) / len(original_neighbors)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6957ff7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade dos K vizinhos entre a série original e a reduzida: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Usamos a função para calcular a similaridade dos K vizinhos para as series testadas\n",
    "similarity = calculate_k_similarity(nearest_indices, reduced_nearest_indices)\n",
    "\n",
    "print(f'Similaridade dos K vizinhos entre a série original e a reduzida: {similarity:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32fd635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
