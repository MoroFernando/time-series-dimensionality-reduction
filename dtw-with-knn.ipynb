{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a5a8a1b",
   "metadata": {},
   "source": [
    "Este notebook pretende analisar a preservação estrutural de series temporais após redução de dimensionalidade. Para isso serão selecionados datasets com alta dimensionalidade da biblioteca AEON e aplicados variações do algoritimo do PAA (Piecewise Aggregate Approximation) para redução de dimensionalidade aplicando diferentes taxas perceptuais de redução.\n",
    "\n",
    "Para medir essa preservação da estrutura iremos armazenar uma matriz de similaridade dos K vizinhos mais próximos de cada série temporal antes e depois da redução de dimensionalidade utilizando a distância euclidiana. Assim poderemos comparar se após a redução de dimensionalidade os K vizinhos mais próximos de cada série temporal permanecem os mesmos.\n",
    "\n",
    "A métrica sera normalizada para representar valores entre 0 e 1, onde 1 representa que todos os K vizinhos mais próximos permaneceram os mesmos após a redução de dimensionalidade e 0 representa que nenhum vizinho próximo permaneceu o mesmo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9712d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa algumas bibliotecas necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from aeon.datasets import load_classification\n",
    "from aeon.distances import euclidean_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "433f2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a lista de datasets com alta dimensionalidade a serem usados\n",
    "high_dim_datasets = [\n",
    "  'ACSF1',\n",
    "  'CinCECGTorso',\n",
    "  'EOGHorizontalSignal',\n",
    "  'EOGVerticalSignal',\n",
    "  'EthanolLevel',\n",
    "  'HandOutlines',\n",
    "  'Haptics',\n",
    "  'HouseTwenty',\n",
    "  'InlineSkate',\n",
    "  'Mallat',\n",
    "  'MixedShapesRegularTrain',\n",
    "  'MixedShapesSmallTrain',\n",
    "  'Phoneme',\n",
    "  'PigAirwayPressure',\n",
    "  'PigArtPressure',\n",
    "  'PigCVP',\n",
    "  'Rock',\n",
    "  'SemgHandGenderCh2',\n",
    "  'SemgHandMovementCh2',\n",
    "  'SemgHandSubjectCh2',\n",
    "  'StarLightCurves',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4de2a",
   "metadata": {},
   "source": [
    "Para facilitar a comparação de séries em diferentes escalas, podemos aplicar uma função de normalização nas séries. Assim todas as séries ficarão com média 0 e desvio padrão 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f1d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para facilitar a comparação de séries em diferentes escalas, \n",
    "# podemos aplicar uma função de normalização nas séries.\n",
    "# Assim todas as séries ficarão com média 0 e desvio padrão 1.\n",
    "def znorm(x):\n",
    "  x_znorm = (x - np.mean(x)) / np.std(x)\n",
    "  return x_znorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a6925ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as funções de agregação que podem ser usadas para reduzir a dimensionalidade no PAA\n",
    "aggregations = {\n",
    "    'average': lambda x: np.mean(x),\n",
    "    'median': lambda x: np.median(x),\n",
    "    'max': lambda x: np.max(x),\n",
    "    'min': lambda x: np.min(x),\n",
    "    'sum': lambda x: np.sum(x),\n",
    "    'variance': lambda x: np.var(x),\n",
    "    'std': lambda x: np.std(x),\n",
    "    'iqr': lambda x: np.subtract(*np.percentile(x, [75, 25])),\n",
    "    'first': lambda x: x[0],\n",
    "    'central': lambda x: x[len(x)//2],\n",
    "    'last': lambda x: x[-1],\n",
    "    'max-min': lambda x: np.max(x) - np.min(x),\n",
    "    'avg-max': lambda x: np.abs((np.mean(x) - np.max(x))),\n",
    "    'avg-min': lambda x: np.abs((np.mean(x) - np.min(x))),\n",
    "    'random': lambda x: np.random.choice(x)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f536602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementa o algoritmo PAA (Piecewise Aggregate Approximation)\n",
    "# Recebe uma série temporal 's', o tamanho desejado 'w' e a função de agregação 'agg'\n",
    "def PAA(s, w, agg='average'):\n",
    "    if agg not in aggregations:\n",
    "        raise ValueError(f\"Função de agregação '{agg}' é inválida ou não suportada.\")\n",
    "\n",
    "    n = len(s)\n",
    "    s = np.array(s)\n",
    "\n",
    "    # Aqui criamos n valores uniformemente espaçados entre 0 e w (exclusivo).\n",
    "    # Por exemplo: n=6 e w=2 será [0,0,0,1,1,1]\n",
    "    idx = np.floor(np.linspace(0, w, n, endpoint=False)).astype(int)\n",
    "\n",
    "    # Aqui iteramos sobre o tamanho desejado 'w' e aplicamos uma máscara para selecionar os pontos da série que pertencem a cada segmento.\n",
    "    # Por exemplo: n=6 e w=2, o idx resultante será: \n",
    "    #              [True, True, True, False, False, False] para w = 0\n",
    "    #              Assim podemos selecionar os pontos da série que pertencem a cada segmento.\n",
    "    res = [aggregations[agg](s[idx == i]) for i in range(w)]\n",
    "    # Normalizamos a série reduzida utilizando Z-Norm\n",
    "    res = znorm(res)\n",
    "\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e790e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as taxas de redução de dimensionalidade a serem testadas\n",
    "reduction_rates = [\n",
    "    0.9,\n",
    "    0.8,\n",
    "    0.7,\n",
    "    0.6,\n",
    "    0.5,\n",
    "    0.4,\n",
    "    0.3,\n",
    "    0.2,\n",
    "    0.1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54520ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa a função para calcular distâncias de forma eficiente\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Função para calcular a matriz de distância entre todas as séries temporais em um conjunto de dados X\n",
    "def get_distance_matrix(X):\n",
    "    # 1. Cria uma cópia de X para evitar modificar o original\n",
    "    X_cp = np.array(X)\n",
    "\n",
    "    # 2. Remove dimensões unitárias para garantir que X seja 2D (N x M)\n",
    "    # Por se tratar de séries temporais univariadas, o formato original é \n",
    "    # (N x 1 x M) e sera convertido para (N x M)\n",
    "    X_2d = X_cp.squeeze()\n",
    "\n",
    "    # 3. pdist calcula as N*(N-1)/2 distâncias únicas\n",
    "    condensed_dist = pdist(X_2d, metric='euclidean')\n",
    "\n",
    "    # 4. squareform monta a matriz N x N simétrica completa\n",
    "    distance_matrix = squareform(condensed_dist)\n",
    "    \n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c53c6a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter os K vizinhos mais proximos de uma serie (s) por meio de uma matriz de distâncias\n",
    "def get_k_nearest_neighbors(dist_matrix, point_idx, k):    \n",
    "    # 1. Pega a linha de distâncias para o nosso ponto\n",
    "    distances_from_point = dist_matrix[point_idx]\n",
    "    \n",
    "    # 2. Obtém os índices ordenados pela distância\n",
    "    #    Ex: sorted_indices[0] será o próprio point_idx (dist 0)\n",
    "    sorted_indices = np.argsort(distances_from_point)\n",
    "    \n",
    "    # 3. Pega os K vizinhos mais próximos.\n",
    "    #    Pulamos o primeiro índice (posição 0), pois é o próprio ponto.\n",
    "    #    Pegamos da posição 1 (o vizinho mais próximo) até k+1.\n",
    "    k_nearest_indices = sorted_indices[1 : k + 1]\n",
    "    \n",
    "    # 4. Pega as distâncias correspondentes a esses vizinhos\n",
    "    k_nearest_distances = distances_from_point[k_nearest_indices]\n",
    "    \n",
    "    return k_nearest_indices, k_nearest_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd970050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: HouseTwenty, Shape original: (159, 1, 2000)\n",
      "Normalizando séries com sua função znorm...\n",
      "Calculando a matriz de distância...\n",
      "Shape final: (159, 159)\n",
      "\n",
      "Matriz de Distância (Início):\n",
      "[[ 0.         56.13328025 54.34043454 54.15500871 67.07087115]\n",
      " [56.13328025  0.         61.12841113 62.47950359 63.62144155]\n",
      " [54.34043454 61.12841113  0.         46.69631666 66.82907255]\n",
      " [54.15500871 62.47950359 46.69631666  0.         67.17988739]\n",
      " [67.07087115 63.62144155 66.82907255 67.17988739  0.        ]]\n",
      "Séries mais próximas da série 5: [139 107   3] com distâncias [44.33162092 46.05375307 47.36015159]\n"
     ]
    }
   ],
   "source": [
    "d = 'HouseTwenty'\n",
    "X, y = load_classification(d, split=None)\n",
    "\n",
    "print(f'Dataset: {d}, Shape original: {X.shape}')\n",
    "\n",
    "print(\"Normalizando séries com sua função znorm...\")\n",
    "X_norm = np.array([[znorm(s[0])] for s in X])\n",
    "\n",
    "print(\"Calculando a matriz de distância...\")\n",
    "dist_matrix = get_distance_matrix(X_norm)\n",
    "\n",
    "print(f\"Shape final: {dist_matrix.shape}\")\n",
    "\n",
    "print(\"\\nMatriz de Distância (Início):\")\n",
    "print(dist_matrix[:5, :5])\n",
    "\n",
    "#Exibe os k vizinhos mais próximos de uma série específica\n",
    "series_index = 5  # Índice da série que queremos analisar\n",
    "k = 3\n",
    "\n",
    "nearest_indices, nearest_distances = get_k_nearest_neighbors(dist_matrix, series_index, k)\n",
    "print(f'Séries mais próximas da série {series_index}: {nearest_indices} com distâncias {nearest_distances}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "441cfdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduzindo para w=1000 pontos por série utilizando PAA com agregação median.\n",
      "(159, 159)\n",
      "Séries mais próximas da série 5: [139 107   3] com distâncias [29.95126277 32.07611833 33.22822385]\n"
     ]
    }
   ],
   "source": [
    "# Reduz a dimensionalidade das séries utilizando PAA e calcula a nova matriz de distâncias\n",
    "d = 'HouseTwenty'\n",
    "X, y = load_classification(d, split=None)\n",
    "\n",
    "agg = 'median'\n",
    "reduction_rate = 0.5\n",
    "w = int(len(X[0][0]) * (1 - reduction_rate))\n",
    "\n",
    "print(f'Reduzindo para w={w} pontos por série utilizando PAA com agregação {agg}.')\n",
    "X_reduced = np.array([[PAA(s[0], w, agg=agg)] for s in X])\n",
    "\n",
    "# Inicializa a nova matriz de distâncias\n",
    "dist_matrix_reduced = get_distance_matrix(X_reduced)\n",
    "\n",
    "# Exibe a nova matriz de distâncias\n",
    "print(dist_matrix_reduced.shape)\n",
    "\n",
    "# Exibe as k=3 series mais próximas de uma series qualquer do dataset reduzido\n",
    "series_index = 5  # Índice da série que queremos analisar\n",
    "k = 3\n",
    "\n",
    "nearest_indices, nearest_distances = get_k_nearest_neighbors(dist_matrix_reduced, series_index, k)\n",
    "print(f'Séries mais próximas da série {series_index}: {nearest_indices} com distâncias {nearest_distances}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0a980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
